<!DOCTYPE html>
<html>

<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
    <title>Yu-Hsiang Lin</title>

    <style type="text/css">
        body {
            font-family: 'Helvetica', 'Arial', sans-serif;
            margin: 3em auto;
            width: 900px;
        }

        ul {
            list-style-type: none;
            padding-left: 2em;
        }

        h2 {
            margin-top: 2em;
        }

        div.contactbox {
            margin-left: 1em;
        }
    </style>
</head>

<body>

<div id="menu" align="center">
    <p><h3>
    <a href="./index.html">Home</a> &nbsp;|&nbsp;
    <a href="./experiences.html">Experiences</a> &nbsp;|&nbsp;
    <a href="./projects.html">Projects</a> &nbsp;|&nbsp;
    <a href="./publications.html">Publications</a> &nbsp;|&nbsp;
    <a href="./activities.html">Professional Activities</a>
    </h3></p>
</div>

<br>

<div style="width: 800px" align="left">
<table> 
<tbody>
<tr> 
<td>
<div style="padding: 5px">
<img src="./home_files/20180701_crop.png" width="150">
</div>
</td>
<td>
<div class="contactbox">
<p><h1>Yu-Hsiang Lin</h1></p>
<p>
Email: hitr2997925@gmail.com<br>
LinkedIn: <a href="https://www.linkedin.com/in/yhl2997925/">https://www.linkedin.com/in/yhl2997925/</a><br>
GitHub: <a href="https://github.com/yuhsianglin">https://github.com/yuhsianglin</a>
</p>
</div>
</td>
</tr> 
</tbody>
</table>
</div>


<p style="text-align: justify">
    I am an applied scientist at <a href="https://www.aboutamazon.com">Amazon</a>. I enjoy working on scientific and engineering projects in machine learning, mostly natural language processing and large language models (LLMs) recently, and product search in the past.
</p>
<p style="text-align: justify">
    In Amazon Alexa, I built various capabilities of LLMs including instruction following, creative writing, retrieval-augmented generation (RAG), and prompt orchestration. I worked on several aspects of model building such as supervised fine-tuning, alignment tuning (reward modeling, PPO, DPO), curriculum learning, human preference evaluation, LLM-as-a-judge evaluation, model-in-the-loop self-instruct data generation, self-critique-and-revise data improvement, prompt engineering, etc.
</p>
<p style="text-align: justify">
    In Amazon Search, I built neural language generative models to help customers find relevant new products, introduced graph neural networks and new model training methods to address the low-resource learning problem in product search, and developed the online ranking features to improve the search performance in long-tail queries. I also built the data pipeline that generates online A/B testing metrics used by all teams across Amazon, and a feature build that publishes the new product features to the search index. During my internship I developed the two-phase ranking model for Amazon Business.
<p style="text-align: justify">
    I had my master in the <a href="https://www.lti.cs.cmu.edu/">Language Technologies Institute</a> at <a href="http://www.cmu.edu/index.shtml">Carnegie Mellon University</a> and Ph.D. in physics in <a href="http://www.ntu.edu.tw/">National Taiwan University</a>. My master training focused on machine learning, deep learning, natural language processing, and distributed systems. My Ph.D. research was on high-energy physics and astrophysics.
</p>
<p style="text-align: justify">
    At Carnegie Mellon University I worked on topics in natural language processing including cross-lingual transfer for low-resource languages, advised by <a href="http://www.phontron.com/">Graham Neubig</a> (<a href="https://www.aclweb.org/anthology/P19-1301/">ACL 2019</a>). I also worked on reinforcement learning, generative adversarial networks, and structured prediction. At National Taiwan University I worked with <a href="https://www.csie.ntu.edu.tw/~cjlin/">Chih-Jen Lin</a> on the second-order optimization methods for deep neural networks (<a href="https://www.mitpressjournals.org/doi/full/10.1162/neco_a_01088">Neural Computation 2018</a>).
</p>


</body>

</html>
